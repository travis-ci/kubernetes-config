apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ include "macstadium-worker.fullname" . }}
  labels:
    app.kubernetes.io/name: {{ include "macstadium-worker.name" . }}
    helm.sh/chart: {{ include "macstadium-worker.chart" . }}
    app.kubernetes.io/instance: {{ .Release.Name }}
    app.kubernetes.io/managed-by: {{ .Release.Service }}
spec:
  replicas: {{ .Values.replicaCount }}
  selector:
    matchLabels:
      app.kubernetes.io/name: {{ include "macstadium-worker.name" . }}
      app.kubernetes.io/instance: {{ .Release.Name }}
  template:
    metadata:
      labels:
        app.kubernetes.io/name: {{ include "macstadium-worker.name" . }}
        app.kubernetes.io/instance: {{ .Release.Name }}
    spec:
      containers:
      - name: {{ .Chart.Name }}
        image: "{{ .Values.image.repository }}:{{ .Values.image.tag }}"
        imagePullPolicy: {{ .Values.image.pullPolicy }}
        env:

        - name: JUPITER_BRAIN_AUTH_TOKEN
          valueFrom:
            secretKeyRef:
              name: {{ include "macstadium-worker.jupiterbrainname" . }}
              key: JUPITER_BRAIN_AUTH_TOKEN
        - name: TRAVIS_WORKER_JUPITERBRAIN_ENDPOINT
          value: http://$(JUPITER_BRAIN_AUTH_TOKEN)@{{ include "macstadium-worker.jupiterbrainname" . }}/

        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace

        - name: TRAVIS_WORKER_LIBRATO_SOURCE
          value: $(POD_NAMESPACE)-$(POD_NAME)
        - name: TRAVIS_WORKER_HOSTNAME
          value: $(POD_NAME).$(POD_NAMESPACE)
        - name: TRAVIS_WORKER_CONCURRENT_JOBS_NAME
          value: $(POD_NAME)

        # The worker secret will have these prefixed with TRAVIS_WORKER,
        # but the AWS library wants these variable names instead.
        - name: AWS_ACCESS_KEY_ID
          value: $(TRAVIS_WORKER_AWS_ACCESS_KEY_ID)
        - name: AWS_SECRET_ACCESS_KEY
          value: $(TRAVIS_WORKER_AWS_SECRET_ACCESS_KEY)

        envFrom:
        - configMapRef:
            name: {{ template "macstadium-worker.fullname" . }}
        - secretRef:
            name: {{ template "macstadium-worker.fullname" . }}
        volumeMounts:
        - name: travis-vm-ssh-key
          mountPath: "/etc/secret"
          readOnly: true
        - name: concurrent-jobs
          mountPath: "/etc/worker"
          readOnly: true
      volumes:
      - name: travis-vm-ssh-key
        secret:
          secretName: {{ template "macstadium-worker.fullname" . }}-vm-key
      - name: concurrent-jobs
        configMap:
          name: {{ template "macstadium-worker.fullname" . }}-concurrency
      terminationGracePeriodSeconds: 7200
  strategy:
    rollingUpdate:
      # We can probably handle extra jobs while a worker is shutting down,
      # so allow an extra worker to be brought up while one is being shutdown.
      maxUnavailable: 0
      maxSurge: 1
